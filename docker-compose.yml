services:
  chromadb:
    image: chromadb/chroma:latest
    container_name: rag_chromadb
    ports:
      - "8000:8000"
    volumes:
      - chroma_data:/chroma/chroma
    environment:
      - CHROMA_SERVER_HOST=0.0.0.0
      - CHROMA_SERVER_HTTP_PORT=8000
      - ANONYMIZED_TELEMETRY=False
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    restart: unless-stopped
    networks:
      - rag_network
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '0.5'
        reservations:
          memory: 512M

  rag-service:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: rag_service
    ports:
      - "${APP_PORT:-8001}:${APP_PORT:-8001}"
    depends_on:
      - chromadb
    volumes:
      # Main data directories
      - ./data:/data
      - ./data/input:/data/input
      - ./data/output:/data/output
      - ./data/processed:/data/processed
      - ./data/obsidian:/data/obsidian
      # Temporary processing
      - rag_temp:/tmp/rag_processing
    environment:
      # Server configuration
      - APP_HOST=${APP_HOST:-0.0.0.0}
      - APP_PORT=${APP_PORT:-8001}

      # ChromaDB connection
      - CHROMA_HOST=chromadb
      - CHROMA_PORT=8000
      - COLLECTION_NAME=documents

      # File processing
      - WATCH_FOLDER=/data/input
      - MARKDOWN_FOLDER=/data/output
      - OBSIDIAN_VAULT_PATH=/data/obsidian
      - CHUNK_SIZE=1000
      - CHUNK_OVERLAP=200
      - MAX_FILE_SIZE_MB=50

      # LLM Configuration
      - DEFAULT_LLM=groq
      - FALLBACK_LLM=anthropic
      - EMERGENCY_LLM=openai
      - LLM_TEMPERATURE=0.7
      - LLM_MAX_RETRIES=3

      # OCR Configuration
      - USE_OCR=true
      - OCR_PROVIDER=tesseract
      - OCR_LANGUAGES=eng,deu,fra,spa

      # Feature flags
      - ENABLE_FILE_WATCH=true
      - CREATE_OBSIDIAN_LINKS=true
      - HIERARCHY_DEPTH=3

      # Platform
      - DOCKER_CONTAINER=true
      - SUPPORTED_LANGUAGES=en,de,fr,es

      # LLM API Keys (LiteLLM will auto-detect these)
      - GROQ_API_KEY=${GROQ_API_KEY:-}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY:-}
      - OPENAI_API_KEY=${OPENAI_API_KEY:-}
      - GOOGLE_API_KEY=${GOOGLE_API_KEY:-}
      - COHERE_API_KEY=${COHERE_API_KEY:-}
      - MISTRAL_API_KEY=${MISTRAL_API_KEY:-}
      - REPLICATE_API_TOKEN=${REPLICATE_API_TOKEN:-}
      - HUGGINGFACE_API_KEY=${HUGGINGFACE_API_KEY:-}

      # Cloud OCR Configuration (optional - add API keys in .env)
      - GOOGLE_VISION_API_KEY=${GOOGLE_VISION_API_KEY:-}
      - AZURE_CV_ENDPOINT=${AZURE_CV_ENDPOINT:-}
      - AZURE_CV_API_KEY=${AZURE_CV_API_KEY:-}
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID:-}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY:-}
      - AWS_REGION=${AWS_REGION:-us-east-1}

      # Enhanced Features
      - ENABLE_ENHANCED_SEARCH=true
      - ENABLE_HYBRID_RETRIEVAL=true
      - ENABLE_RERANKING=true
      - ENABLE_QUALITY_TRIAGE=true
      - ENABLE_CLOUD_OCR=true

    env_file:
      - .env
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "python", "-c", "import os, requests; port = os.getenv('APP_PORT', '8001'); requests.get(f'http://localhost:{port}/health', timeout=5)"]
      interval: 30s
      timeout: 15s
      retries: 5
      start_period: 45s
    networks:
      - rag_network
    # Resource limits for better performance
    deploy:
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 1G

  # Production-ready reverse proxy
  nginx:
    image: nginx:alpine
    container_name: rag_nginx
    ports:
      - "80:80"
      - "443:443"
    depends_on:
      - rag-service
    volumes:
      - ./nginx.conf:/etc/nginx/conf.d/default.conf:Z
      - ./ssl:/etc/nginx/ssl:ro  # For HTTPS certificates
    restart: unless-stopped
    networks:
      - rag_network
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 256M
          cpus: '0.25'
        reservations:
          memory: 64M

  # Optional: Web UI (uncomment if you want a dedicated UI service)
  # rag-ui:
  #   build:
  #     context: ./ui
  #     dockerfile: Dockerfile
  #   container_name: rag_ui
  #   ports:
  #     - "3000:3000"
  #   depends_on:
  #     - rag-service
  #   environment:
  #     - REACT_APP_API_URL=http://localhost/api
  #   restart: unless-stopped
  #   networks:
  #     - rag_network

volumes:
  chroma_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ./volumes/chroma_data
  rag_temp:
    driver: local

networks:
  rag_network:
    driver: bridge